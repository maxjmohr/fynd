import os
import sys
parent_dir = os.path.dirname(os.path.realpath(__file__+"/../../"))
sys.path.append(parent_dir)

import pandas as pd
import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.options import Options
import time
import pyperclip
import requests
import re
from textwrap import wrap
from bs4 import BeautifulSoup

# Clean text by removing unnecessary symbols like HTML tags
CLEANR = re.compile('<.*?>')
replace_str = "S. <em>Aktuelles</em></p><p>"

# Small helper function the clean text
def cleanhtml(raw_html):
    remove_notice = raw_html.replace(replace_str, "")
    cleantext = re.sub(CLEANR, ' ', remove_notice)
    return cleantext


# set up selenium driver
options = Options()
options.headless = True
options.add_argument('--disable-blink-features=AutomationControlled')

# Get content from website"
travel_warning = requests.get("https://en.wikivoyage.org/wiki/Paris")
            
# Extract text from website content
search_text = travel_warning.text
print(len(search_text))

# Search for paragraph in the text
#safety = re.match('<span class="mw-headline" id="See">See</span>(.*?)<span class="mw-headline" id="Do">Do</span>', search_text)
section_start = search_text.find('<span class="mw-headline" id="See">See</span>')
section_end = search_text.find('<span class="mw-headline" id="Do">Do</span>')
see_section = search_text[section_start:section_end]
#print(search_text[section_start:section_end])
soup = BeautifulSoup(see_section)
paragraphs = soup.findAll('p')
lists = soup.findAll('ul')
print(lists[0])
print(len(lists))
#ids = re.search('id="(.*)"', str(lists[0]))
places = re.findall(r'id=".+?"',str(lists[0]))
print(places)
descriptions = re.findall(r'class="note listing-content">.+?</bdi>',str(lists[0]))
print(descriptions)
""" ids = []
for l in lists:
    soup_l = BeautifulSoup(l)
    ids.append(soup_l.findAll("id"))
print(lists) """